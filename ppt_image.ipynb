{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving slide 0 to Output/ToImage_0.png\n",
      "Saving slide 1 to Output/ToImage_1.png\n",
      "Saving slide 2 to Output/ToImage_2.png\n",
      "Saving slide 3 to Output/ToImage_3.png\n",
      "Saving slide 4 to Output/ToImage_4.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from spire.presentation.common import *\n",
    "from spire.presentation import *\n",
    "\n",
    "# Create a Presentation object\n",
    "presentation = Presentation()\n",
    "\n",
    "# Load a PowerPoint presentation\n",
    "presentation.LoadFromFile(\"Project Delivery.pptx\")\n",
    "\n",
    "# Create the Output directory if it doesn't exist\n",
    "output_directory = \"Output\"\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Loop through the slides in the presentation\n",
    "for i, slide in enumerate(presentation.Slides):\n",
    "    # Specify the output file name\n",
    "    fileName = f\"{output_directory}/ToImage_{i}.png\"  # Use forward slashes\n",
    "    print(\"Saving slide\", i, \"to\", fileName)  # Print debug information\n",
    "    # Save each slide as a PNG image\n",
    "    image = slide.SaveAsImage()\n",
    "    image.Save(fileName)\n",
    "    image.Dispose()\n",
    "\n",
    "presentation.Dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "image_elements = []\n",
    "output_path = \"C:\\\\Users\\\\DELL\\\\PDF_Chat_MM\\\\Output\"\n",
    "\n",
    "# Function to encode images\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    return encoded_image\n",
    "\n",
    "for image_file in os.listdir(output_path):\n",
    "    if image_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(output_path, image_file)\n",
    "        encoded_image = encode_image(image_path)\n",
    "        image_elements.append(encoded_image)\n",
    "print(len(image_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import openai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import google.generativeai as genai\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "chain_gpt = ChatOpenAI(model=\"gpt-3.5-turbo\", max_tokens=1024)\n",
    "chain_gemini_vision = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\",max_output_tokens=1024)\n",
    "\n",
    "# Function for image content\n",
    "def content_image(encoded_image):\n",
    "    prompt = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": \"Extract full information in the image.If there is table you need to read it as a table.\"},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                },\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    response = chain_gemini_vision.invoke([prompt])\n",
    "    return response.content\n",
    "\n",
    "# Function for image summaries\n",
    "def summarize_image(encoded_image):\n",
    "    prompt = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": \"Describe the contents of this image.\"},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                },\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    response = chain_gemini_vision.invoke([prompt])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th element of images processed.\n",
      " The image contains a puzzle graphic with five pieces. Each piece has a different color and contains text. The text in the puzzle pieces, from top to bottom, is:\n",
      "1. Program Director/Delivery Manager\n",
      "2. Program Manager\n",
      "3. Enterprise Architect/Solution Architects\n",
      "4. Team Managers\n",
      "5. Developers/Testers\n",
      "1th element of images processed.\n",
      " Project Delivery Team\n",
      "1. Program Director/Delivery Manager\n",
      "2. Program Manager\n",
      "3. Enterprise Architect/Solution Architects\n",
      "4. Team Managers\n",
      "5. Developers/Testers\n",
      "2th element of images processed.\n",
      " The image shows a slide titled \"SDLC Waterfall Framework\". \n",
      "There are 5 puzzle pieces in the image. \n",
      "The top left puzzle piece says \"Project Kick off\".\n",
      "The top right puzzle piece says \"Design\".\n",
      "The bottom left puzzle piece says \"Requirements Analysis\".\n",
      "The bottom right puzzle piece says \"Deployment\".\n",
      "The puzzle piece in the middle says \"Development & Testing\" on the top and \"HLD\" and \"LLD\" on the bottom.\n",
      "2th element of images processed.\n",
      " SDLC Waterfall Framework\n",
      "\n",
      "1. Project Kick off\n",
      "2. Requirements Analysis\n",
      "3. Design\n",
      "4. Development & Testing\n",
      "5. Deployment\n",
      "6. Maintenance\n",
      "\n",
      "HLD - High Level Design\n",
      "LLD - Low Level Design\n",
      "3th element of images processed.\n",
      "  내용은 다음과 같습니다.\n",
      "- 제목: SDLC Agile Framework\n",
      "- 이미지: 원형 다이어그램\n",
      "  - 원의 중심: Agile software development cycle\n",
      "  - 원의 6개 영역: Plan, Design, Develop, Test, Evaluate, Meet\n",
      "  - 각 영역은 화살표로 연결되어 있음\n",
      "3th element of images processed.\n",
      " SDLC Agile Framework\n",
      "Agile software development cycle\n",
      "1.Plan\n",
      "2.Design\n",
      "3.Develop\n",
      "4.Test\n",
      "5.Evaluate\n",
      "6.Meet\n",
      "4th element of images processed.\n",
      " The image contains a table of annual revenues for a company. The table has five columns: Year, Americas, EMEA, Asia, Far East, and Total. The years range from 2015 to 2023. The revenue figures are in billions of US dollars. The company had the highest revenue in 2023, with 5.11 billion US dollars. The lowest revenue was in 2015, with 2.58 billion US dollars.\n",
      "4th element of images processed.\n",
      " ### Annual Revenue\n",
      "\n",
      "| Year | Americas | EMEA | Asia | Far East | Total |\n",
      "|---|:---:|:---:|:---:|:---:|:---:|\n",
      "| 2015 | 1.29 | 0.52 | 0.52 | 0.26 | 2.58 |\n",
      "| 2016 | 1.54 | 0.61 | 0.61 | 0.31 | 3.07 |\n",
      "| 2017 | 1.79 | 0.72 | 0.72 | 0.36 | 3.58 |\n",
      "| 2018 | 1.98 | 0.79 | 0.79 | 0.40 | 3.97 |\n",
      "| 2019 | 2.18 | 0.87 | 0.87 | 0.44 | 4.35 |\n",
      "| 2020 | 2.27 | 0.91 | 0.91 | 0.45 | 4.54 |\n",
      "| 2021 | 2.09 | 0.84 | 0.84 | 0.42 | 4.18 |\n",
      "| 2022 | 2.35 | 0.94 | 0.94 | 0.47 | 4.69 |\n",
      "| 2023 | 2.56 | 1.02 | 1.02 | 0.51 | 5.11 |\n",
      "5th element of images processed.\n",
      " The image is a bar chart that shows the global market size from 2015 to 2023. The market size is divided into four regions: Americas, EMEA, Asia, and Far East. The y-axis shows the market size in billions of US dollars, while the x-axis shows the year.\n",
      "\n",
      "The market size has been increasing steadily since 2015. In 2015, the market size was 8 billion US dollars. By 2023, the market size is expected to reach 15 billion US dollars.\n",
      "\n",
      "The Americas region has the largest market share, followed by the EMEA region. The Asia and Far East regions have the smallest market shares.\n",
      "5th element of images processed.\n",
      " # Global Market Size\n",
      "### Market Size Global ( in Billion US$)\n",
      "\n",
      "| Year | Americas | EMEA | Asia | Far East | Total |\n",
      "|---|---|---|---|---|---|\n",
      "| 2015 | 4.0 | 1.8 | 0.5 | 2.7 | 8.0 |\n",
      "| 2016 | 4.8 | 2.1 | 1.0 | 2.6 | 9.5 |\n",
      "| 2017 | 5.3 | 2.3 | 1.1 | 2.1 | 10.5 |\n",
      "| 2018 | 6.0 | 2.6 | 1.2 | 2.2 | 12.0 |\n",
      "| 2019 | 7.0 | 3.1 | 1.4 | 2.5 | 14.0 |\n",
      "| 2020 | 6.5 | 2.9 | 1.3 | 2.3 | 13.0 |\n",
      "| 2021 | 6.0 | 2.6 | 1.2 | 2.2 | 12.0 |\n",
      "| 2022 | 6.8 | 3.0 | 1.4 | 2.3 | 13.5 |\n",
      "| 2023 | 7.5 | 3.3 | 1.5 | 2.7 | 15.0 |\n"
     ]
    }
   ],
   "source": [
    "# Processing image elements with feedback and sleep\n",
    "image_summaries = []\n",
    "image_content=[]\n",
    "for i, ie in enumerate(image_elements):\n",
    "    summary = summarize_image(ie)\n",
    "    image_summaries.append(summary)\n",
    "    contents = content_image(ie)\n",
    "    image_content.append(contents)\n",
    "\n",
    "    print(f\"{i + 1}th element of images processed.\")\n",
    "    print(summary)\n",
    "\n",
    "    print(f\"{i + 1}th element of images processed.\")\n",
    "    print(contents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.schema.document import Document\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the vector store and storage layer\n",
    "vectorstore = Chroma(collection_name=\"summaries\", embedding_function=OpenAIEmbeddings())\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# Initialize the retriever\n",
    "retriever = MultiVectorRetriever(vectorstore=vectorstore, docstore=store, id_key=id_key)\n",
    "\n",
    "# Function to add documents to the retriever\n",
    "def add_documents_to_retriever(summaries, original_contents):\n",
    "    doc_ids = [str(uuid.uuid4()) for _ in summaries]\n",
    "    summary_docs = [\n",
    "        Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "        for i, s in enumerate(summaries)\n",
    "    ]\n",
    "    retriever.vectorstore.add_documents(summary_docs)\n",
    "    retriever.docstore.mset(list(zip(doc_ids, original_contents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add image summaries\n",
    "add_documents_to_retriever(image_summaries, image_content) # hopefully real images soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ### Annual Revenue\\n\\n| Year | Americas | EMEA | Asia | Far East | Total |\\n|---|:---:|:---:|:---:|:---:|:---:|\\n| 2015 | 1.29 | 0.52 | 0.52 | 0.26 | 2.58 |\\n| 2016 | 1.54 | 0.61 | 0.61 | 0.31 | 3.07 |\\n| 2017 | 1.79 | 0.72 | 0.72 | 0.36 | 3.58 |\\n| 2018 | 1.98 | 0.79 | 0.79 | 0.40 | 3.97 |\\n| 2019 | 2.18 | 0.87 | 0.87 | 0.44 | 4.35 |\\n| 2020 | 2.27 | 0.91 | 0.91 | 0.45 | 4.54 |\\n| 2021 | 2.09 | 0.84 | 0.84 | 0.42 | 4.18 |\\n| 2022 | 2.35 | 0.94 | 0.94 | 0.47 | 4.69 |\\n| 2023 | 2.56 | 1.02 | 1.02 | 0.51 | 5.11 |']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can retrieve this table\n",
    "retriever.get_relevant_documents(\n",
    "    \" what is the anual revenue of asia in 2020?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context, which can include text, images and tables:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The annual revenue of Asia in 2020 was $0.91 billion.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "     \"\"\"what is the anual revenue of asia in 2020?\n",
    "     use the following information to answer the question:\n",
    "[' ### Annual Revenue\\n\\n| Year | Americas | EMEA | Asia | Far East | Total |\\n|---|:---:|:---:|:---:|:---:|:---:|\\n| 2015 | 1.29 | 0.52 | 0.52 | 0.26 | 2.58 |\\n| 2016 | 1.54 | 0.61 | 0.61 | 0.31 | 3.07 |\\n| 2017 | 1.79 | 0.72 | 0.72 | 0.36 | 3.58 |\\n| 2018 | 1.98 | 0.79 | 0.79 | 0.40 | 3.97 |\\n| 2019 | 2.18 | 0.87 | 0.87 | 0.44 | 4.35 |\\n| 2020 | 2.27 | 0.91 | 0.91 | 0.45 | 4.54 |\\n| 2021 | 2.09 | 0.84 | 0.84 | 0.42 | 4.18 |\\n| 2022 | 2.35 | 0.94 | 0.94 | 0.47 | 4.69 |\\n| 2023 | 2.56 | 1.02 | 1.02 | 0.51 | 5.11 |'] \"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
